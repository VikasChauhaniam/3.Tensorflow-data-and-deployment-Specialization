{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "migrating_feature_columns.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-23gBrt4x2B"
      },
      "source": [
        "##### Copyright 2021 The TensorFlow Authors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "HMUDt0CiUJk9"
      },
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77z2OchJTk0l"
      },
      "source": [
        "# Migrating feature_columns to TF2's Keras Preprocessing Layers\n",
        "\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://www.tensorflow.org/guide/migrate/migrating_feature_columns\">\n",
        "    <img src=\"https://www.tensorflow.org/images/tf_logo_32px.png\" />\n",
        "    View on TensorFlow.org</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_feature_columns.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />\n",
        "    Run in Google Colab</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a target=\"_blank\" href=\"https://github.com/tensorflow/docs/blob/master/site/en/guide/migrate/migrating_feature_columns.ipynb\">\n",
        "    <img src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />\n",
        "    View source on GitHub</a>\n",
        "  </td>\n",
        "  <td>\n",
        "    <a href=\"https://storage.googleapis.com/tensorflow_docs/docs/site/en/guide/migrate/migrating_feature_columns.ipynb\"><img src=\"https://www.tensorflow.org/images/download_logo_32px.png\" />Download notebook</a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5jGPDA2PDPI"
      },
      "source": [
        "Training a model will usually come with some amount of feature preprocessing, particularly when dealing with structured data. When training a `tf.estimator.Estimator` in TF1, this feature preprocessing is usually done with the `tf.feature_column` API. In TF2, this preprocessing can be done directly with Keras layers, called _preprocessing layers_.\n",
        "\n",
        "In this migration guide, you will perform some common feature transformations using both feature columns and preprocessing layers, followed by training a complete model with both APIs.\n",
        "\n",
        "First, start with a couple of necessary imports,"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iE0vSfMXumKI"
      },
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf1\n",
        "import math"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NVPYTQAWtDwH"
      },
      "source": [
        "and add a utility for calling a feature column for demonstration:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LAaifuuytJjM"
      },
      "source": [
        "def call_feature_columns(feature_columns, inputs):\n",
        "  # This is a convenient way to call a `feature_column` outside of an estimator\n",
        "  # to display its output.\n",
        "  feature_layer = tf1.keras.layers.DenseFeatures(feature_columns)\n",
        "  return feature_layer(inputs)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZJnw07hYDGYt"
      },
      "source": [
        "## Input handling\n",
        "\n",
        "To use feature columns with an estimator, model inputs are always expected to be a dictionary of tensors:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0WUpQxsKEzf"
      },
      "source": [
        "input_dict = {\n",
        "  'foo': tf.constant([1]),\n",
        "  'bar': tf.constant([0]),\n",
        "  'baz': tf.constant([-1])\n",
        "}"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYsC6H_BJ8l3"
      },
      "source": [
        "Each feature column needs to be created with a key to index into the source data. The output of all feature columns is concatenated and used by the estimator model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fvIe3V8Ffjt",
        "outputId": "9544787c-0fd4-4e99-921b-766f80d2b75a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "columns = [\n",
        "  tf1.feature_column.numeric_column('foo'),\n",
        "  tf1.feature_column.numeric_column('bar'),\n",
        "  tf1.feature_column.numeric_column('baz'),\n",
        "]\n",
        "call_feature_columns(columns, input_dict)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 3), dtype=float32, numpy=array([[ 0., -1.,  1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hvPfCK2XGTyl"
      },
      "source": [
        "In Keras, model input is much more flexible. A `tf.keras.Model` can handle a single tensor input, a list of tensor features, or a dictionary of tensor features. You can handle dictionary input by passing a dictionary of `tf.keras.Input` on model creation. Inputs will not be concatenated automatically, which allows them to be used in much more flexible ways. They can be concatenated with `tf.keras.layers.Concatenate`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sYWENkgLWJ2",
        "outputId": "9c222acc-307c-4f25-888a-fdda92c82067",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inputs = {\n",
        "  'foo': tf.keras.Input(shape=()),\n",
        "  'bar': tf.keras.Input(shape=()),\n",
        "  'baz': tf.keras.Input(shape=()),\n",
        "}\n",
        "# Inputs are typically transformed by preprocessing layers before concatenation.\n",
        "outputs = tf.keras.layers.Concatenate()(inputs.values())\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "model(input_dict)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([ 1.,  0., -1.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXkmiuwXTS-B"
      },
      "source": [
        "## One-hot encoding integer IDs\n",
        "\n",
        "A common feature transformation is one-hot encoding integer inputs of a known range. Here is an example using feature columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XasXzOgatgRF",
        "outputId": "98e0135a-0819-4c46-be22-8278581bcd7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "categorical_col = tf1.feature_column.categorical_column_with_identity(\n",
        "    'type', num_buckets=3)\n",
        "indicator_col = tf1.feature_column.indicator_column(categorical_col)\n",
        "call_feature_columns(indicator_col, {'type': [0, 1, 2]})"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              "array([[1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSCkJEQ6U-ru"
      },
      "source": [
        "Using Keras preprocessing layers, these columns can be replaced by a single `tf.keras.layers.CategoryEncoding` layer with `output_mode` set to `'one_hot'`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "799lbMNNuAVz",
        "outputId": "09bbd4bf-ff72-4666-f9e5-e0ec03c07ea2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "one_hot_layer = tf.keras.layers.CategoryEncoding(\n",
        "    num_tokens=3, output_mode='one_hot')\n",
        "one_hot_layer([0, 1, 2])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              "array([[1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kNzRtESU7tga"
      },
      "source": [
        "Note: For large one-hot encodings, it is much more efficient to use a sparse representation of the output. If you pass `sparse=True` to the `CategoryEncoding` layer, the output of the layer will be a `tf.sparse.SparseTensor`, which can be efficiently handled as input to a `tf.keras.layers.Dense` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zf7kjhTiAErK"
      },
      "source": [
        "## Normalizing numeric features\n",
        "\n",
        "When handling continuous, floating-point features with feature columns, you need to use a `tf.feature_column.numeric_column`. In the case where the input is already normalized, converting this to Keras is trivial. You can simply use a `tf.keras.Input` directly into your model, as shown above.\n",
        "\n",
        "A `numeric_column` can also be used to normalize input:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbTMGB9XctGx",
        "outputId": "a9d35d91-e77e-45cc-83eb-5ab675df7523",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def normalize(x):\n",
        "  mean, variance = (2.0, 1.0)\n",
        "  return (x - mean) / math.sqrt(variance)\n",
        "numeric_col = tf1.feature_column.numeric_column('col', normalizer_fn=normalize)\n",
        "call_feature_columns(numeric_col, {'col': tf.constant([[0.], [1.], [2.]])})"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
              "array([[-2.],\n",
              "       [-1.],\n",
              "       [ 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9cyhPR_drOz"
      },
      "source": [
        "In contrast, with Keras, this normalization can be done with `tf.keras.layers.Normalization`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8bcgG-yOdqUH",
        "outputId": "4bcf600e-3a2e-4fc6-87c7-97a3a4eca2b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "normalization_layer = tf.keras.layers.Normalization(mean=2.0, variance=1.0)\n",
        "normalization_layer(tf.constant([[0.], [1.], [2.]]))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 1), dtype=float32, numpy=\n",
              "array([[-2.],\n",
              "       [-1.],\n",
              "       [ 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1InD_4QLKU-"
      },
      "source": [
        "## Bucketizing and one-hot encoding numeric features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5e0b8iOLRzd"
      },
      "source": [
        "Another common transformation of continuous, floating point inputs is to bucketize then to integers of a fixed range.\n",
        "\n",
        "In feature columns, this can be achieved with a `tf.feature_column.bucketized_column`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_rbx6qQ-LQx7",
        "outputId": "f5df11d2-c7f6-4f00-faf1-3f333e0675bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "numeric_col = tf1.feature_column.numeric_column('col')\n",
        "bucketized_col = tf1.feature_column.bucketized_column(numeric_col, [1, 4, 5])\n",
        "call_feature_columns(bucketized_col, {'col': tf.constant([1., 2., 3., 4., 5.])})\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
              "array([[0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCYu-XtwXahx"
      },
      "source": [
        "In Keras, this can be replaced by `tf.keras.layers.Discretization`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QK1WOG2uVVsL",
        "outputId": "dc3ac87f-31b3-4ee5-da44-e4bac41338ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "discretization_layer = tf.keras.layers.Discretization(bin_boundaries=[1, 4, 5])\n",
        "one_hot_layer = tf.keras.layers.CategoryEncoding(\n",
        "    num_tokens=4, output_mode='one_hot')\n",
        "one_hot_layer(discretization_layer([1., 2., 3., 4., 5.]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 4), dtype=float32, numpy=\n",
              "array([[0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [0., 0., 1., 0.],\n",
              "       [0., 0., 0., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bm9tJZAgpt4"
      },
      "source": [
        "## One-hot encoding string data with a vocabulary\n",
        "\n",
        "Handling string features often requires a vocabulary lookup to translate strings into indices. Here is an example using feature columns to lookup strings and then one-hot encode the indices:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fG_igjhukCO",
        "outputId": "95b67f83-8aeb-4b94-8231-6ab848820929",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vocab_col = tf1.feature_column.categorical_column_with_vocabulary_list(\n",
        "    'sizes',\n",
        "    vocabulary_list=['small', 'medium', 'large'],\n",
        "    num_oov_buckets=0)\n",
        "indicator_col = tf1.feature_column.indicator_column(vocab_col)\n",
        "call_feature_columns(indicator_col, {'sizes': ['small', 'medium', 'large']})"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              "array([[1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rBgllRtY738"
      },
      "source": [
        "Using Keras preprocessing layers, use the `tf.keras.layers.StringLookup` layer with `output_mode` set to `'one_hot'`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arnPlSrWvDMe",
        "outputId": "afe8a4e6-5176-4cf7-ef6d-4cd24e5ca578",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "string_lookup_layer = tf.keras.layers.StringLookup(\n",
        "    vocabulary=['small', 'medium', 'large'],\n",
        "    num_oov_indices=0,\n",
        "    output_mode='one_hot')\n",
        "string_lookup_layer(['small', 'medium', 'large'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 3), dtype=float32, numpy=\n",
              "array([[1., 0., 0.],\n",
              "       [0., 1., 0.],\n",
              "       [0., 0., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f76MVVYO8LB5"
      },
      "source": [
        "Note: For large one-hot encodings, it is much more efficient to use a sparse representation of the output. If you pass `sparse=True` to the `StringLookup` layer, the output of the layer will be a `tf.sparse.SparseTensor`, which can be efficiently handled as input to a `tf.keras.layers.Dense` layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1CmfSXQZHE5"
      },
      "source": [
        "## Embedding string data with a vocabulary\n",
        "\n",
        "For larger vocabularies, an embedding is often needed for good performance. Here is an example embedding a string feature using feature columns:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3RK4HFazxlU",
        "outputId": "9881f9b8-f8a9-4c5b-deb3-8451c6c10c96",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vocab_col = tf1.feature_column.categorical_column_with_vocabulary_list(\n",
        "    'col',\n",
        "    vocabulary_list=['small', 'medium', 'large'],\n",
        "    num_oov_buckets=0)\n",
        "embedding_col = tf1.feature_column.embedding_column(vocab_col, 4)\n",
        "call_feature_columns(embedding_col, {'col': ['small', 'medium', 'large']})"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
              "array([[ 0.66319376, -0.21056402,  0.303586  , -0.21110308],\n",
              "       [ 0.8257001 ,  0.72688496,  0.46996182,  0.45454875],\n",
              "       [ 0.50102824, -0.4308342 , -0.23625204,  0.6327424 ]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aTRVJ6qZZH0"
      },
      "source": [
        "Using Keras preprocessing layers, this can be achieved by combining a `tf.keras.layers.StringLookup` layer and an `tf.keras.layers.Embedding` layer. The default output for the `StringLookup` will be integer indices which can be fed directly into an embedding.\n",
        "\n",
        "Note: The `Embedding` layer contains trainable parameters. While the `StringLookup` layer can be applied to data inside or outside of a model, the `Embedding` must always be part of a trainable Keras model to train correctly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8resGZPo0Fho",
        "outputId": "0a689445-9fcf-473c-ac0b-e401a7eeb54a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "string_lookup_layer = tf.keras.layers.StringLookup(\n",
        "    vocabulary=['small', 'medium', 'large'], num_oov_indices=0)\n",
        "embedding = tf.keras.layers.Embedding(3, 4)\n",
        "embedding(string_lookup_layer(['small', 'medium', 'large']))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 4), dtype=float32, numpy=\n",
              "array([[-0.0014527 , -0.04890234,  0.03667938,  0.03418196],\n",
              "       [-0.03111686,  0.02663663,  0.02343242, -0.03357662],\n",
              "       [ 0.03490419, -0.02863991,  0.01378295,  0.02426371]],\n",
              "      dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I5loEx80MVm"
      },
      "source": [
        "## Complete training example\n",
        "\n",
        "To show a complete training workflow, first prepare some data with three features of different types:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D_7nyBee0ZBV"
      },
      "source": [
        "features = {\n",
        "    'type': [0, 1, 1],\n",
        "    'size': ['small', 'small', 'medium'],\n",
        "    'weight': [2.7, 1.8, 1.6],\n",
        "}\n",
        "labels = [1, 1, 0]\n",
        "predict_features = {'type': [0], 'size': ['foo'], 'weight': [-0.7]}"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_4Xx2c37lqD"
      },
      "source": [
        "Define some common constants for both TF1 and TF2 workflows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3cyfQZ7z8jZh"
      },
      "source": [
        "vocab = ['small', 'medium', 'large']\n",
        "one_hot_dims = 3\n",
        "embedding_dims = 4\n",
        "weight_mean = 2.0\n",
        "weight_variance = 1.0"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ywCgU7CMIfTH"
      },
      "source": [
        "### With feature columns\n",
        "\n",
        "Feature columns must be passed as a list to the estimator on creation, and will be called implicitly during training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsdhlm-uipr1",
        "outputId": "9ec9cb9a-fb4a-40f3-96c1-298c695f915b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "categorical_col = tf1.feature_column.categorical_column_with_identity(\n",
        "    'type', num_buckets=one_hot_dims)\n",
        "# Convert index to one-hot; e.g. [2] -> [0,0,1].\n",
        "indicator_col = tf1.feature_column.indicator_column(categorical_col)\n",
        "\n",
        "# Convert strings to indices; e.g. ['small'] -> [1].\n",
        "vocab_col = tf1.feature_column.categorical_column_with_vocabulary_list(\n",
        "    'size', vocabulary_list=vocab, num_oov_buckets=1)\n",
        "# Embed the indices.\n",
        "embedding_col = tf1.feature_column.embedding_column(vocab_col, embedding_dims)\n",
        "\n",
        "normalizer_fn = lambda x: (x - weight_mean) / math.sqrt(weight_variance)\n",
        "# Normalize the numeric inputs; e.g. [2.0] -> [0.0].\n",
        "numeric_col = tf1.feature_column.numeric_column(\n",
        "    'weight', normalizer_fn=normalizer_fn)\n",
        "\n",
        "estimator = tf1.estimator.DNNClassifier(\n",
        "    feature_columns=[indicator_col, embedding_col, numeric_col],\n",
        "    hidden_units=[1])\n",
        "\n",
        "def _input_fn():\n",
        "  return tf1.data.Dataset.from_tensor_slices((features, labels)).batch(1)\n",
        "\n",
        "estimator.train(_input_fn)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Using default config.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmppluay2wn\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmppluay2wn', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/training/adagrad.py:77: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 0...\n",
            "INFO:tensorflow:Saving checkpoints for 0 into /tmp/tmppluay2wn/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 0...\n",
            "INFO:tensorflow:loss = 0.7307376, step = 0\n",
            "INFO:tensorflow:Calling checkpoint listeners before saving checkpoint 3...\n",
            "INFO:tensorflow:Saving checkpoints for 3 into /tmp/tmppluay2wn/model.ckpt.\n",
            "INFO:tensorflow:Calling checkpoint listeners after saving checkpoint 3...\n",
            "INFO:tensorflow:Loss for final step: 0.7308615.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow_estimator.python.estimator.canned.dnn.DNNClassifier at 0x7f89c421b190>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPIeG_YtfNV1"
      },
      "source": [
        "The feature columns will also be used to transform input data when running inference on the model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-AIIB8CfSqt",
        "outputId": "38ac4fde-20bc-4ccc-df61-5284e141299c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "def _predict_fn():\n",
        "  return tf1.data.Dataset.from_tensor_slices(predict_features).batch(1)\n",
        "\n",
        "next(estimator.predict(_predict_fn))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Restoring parameters from /tmp/tmppluay2wn/model.ckpt-3\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'all_class_ids': array([0, 1], dtype=int32),\n",
              " 'all_classes': array([b'0', b'1'], dtype=object),\n",
              " 'class_ids': array([1]),\n",
              " 'classes': array([b'1'], dtype=object),\n",
              " 'logistic': array([0.51159173], dtype=float32),\n",
              " 'logits': array([0.04637532], dtype=float32),\n",
              " 'probabilities': array([0.4884083, 0.5115918], dtype=float32)}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baMA01cBIivo"
      },
      "source": [
        "### With Keras preprocessing layers\n",
        "\n",
        "Keras preprocessing layers are more flexible in where they can be called. A layer can be applied directly to tensors, used inside a `tf.data` input pipeline, or built directly into a trainable Keras model.\n",
        "\n",
        "In this example, you will apply preprocessing layers inside a `tf.data` input pipeline. To do this, you can define a separate `tf.keras.Model` to preprocess your input features. This model is not trainable, but is a convenient way to group preprocessing layers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMz8RfMQdCZf"
      },
      "source": [
        "inputs = {\n",
        "  'type': tf.keras.Input(shape=(), dtype='int64'),\n",
        "  'size': tf.keras.Input(shape=(), dtype='string'),\n",
        "  'weight': tf.keras.Input(shape=(), dtype='float32'),\n",
        "}\n",
        "# Convert index to one-hot; e.g. [2] -> [0,0,1].\n",
        "type_output = tf.keras.layers.CategoryEncoding(\n",
        "      one_hot_dims, output_mode='one_hot')(inputs['type'])\n",
        "# Convert size strings to indices; e.g. ['small'] -> [1].\n",
        "size_output = tf.keras.layers.StringLookup(vocabulary=vocab)(inputs['size'])\n",
        "# Normalize the numeric inputs; e.g. [2.0] -> [0.0].\n",
        "weight_output = tf.keras.layers.Normalization(\n",
        "      axis=None, mean=weight_mean, variance=weight_variance)(inputs['weight'])\n",
        "outputs = {\n",
        "  'type': type_output,\n",
        "  'size': size_output,\n",
        "  'weight': weight_output,\n",
        "}\n",
        "preprocessing_model = tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRfISnj3NGlW"
      },
      "source": [
        "Note: As an alternative to supplying a vocabulary and normalization statistics on layer creation, many preprocessing layers provide an `adapt()` method for learning layer state directly from the input data. See the [preprocessing guide](https://www.tensorflow.org/guide/keras/preprocessing_layers#the_adapt_method) for more details.\n",
        "\n",
        "You can now apply this model inside a call to `tf.data.Dataset.map`. Please note that the function passed to `map` will automatically be converted into\n",
        "a `tf.function`, and usual caveats for writing `tf.function` code apply (no side effects)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_6xAUnbNREh",
        "outputId": "6a4d133c-f363-48de-8b26-949a46177f9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Apply the preprocessing in tf.data.Dataset.map.\n",
        "dataset = tf.data.Dataset.from_tensor_slices((features, labels)).batch(1)\n",
        "dataset = dataset.map(lambda x, y: (preprocessing_model(x), y),\n",
        "                      num_parallel_calls=tf.data.AUTOTUNE)\n",
        "# Display a preprocessed input sample.\n",
        "next(dataset.take(1).as_numpy_iterator())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'size': array([1]),\n",
              "  'type': array([[1., 0., 0.]], dtype=float32),\n",
              "  'weight': array([0.70000005], dtype=float32)},\n",
              " array([1], dtype=int32))"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_4u3J4NdJ8R"
      },
      "source": [
        "Next, you can define a separate `Model` containing the trainable layers. Note how the inputs to this model now reflect the preprocessed feature types and shapes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kC9OZO5ldmP-"
      },
      "source": [
        "inputs = {\n",
        "  'type': tf.keras.Input(shape=(one_hot_dims,), dtype='float32'),\n",
        "  'size': tf.keras.Input(shape=(), dtype='int64'),\n",
        "  'weight': tf.keras.Input(shape=(), dtype='float32'),\n",
        "}\n",
        "# Since the embedding is trainable, it needs to be part of the training model.\n",
        "embedding = tf.keras.layers.Embedding(len(vocab), embedding_dims)\n",
        "outputs = tf.keras.layers.Concatenate()([\n",
        "  inputs['type'],\n",
        "  embedding(inputs['size']),\n",
        "  tf.expand_dims(inputs['weight'], -1),\n",
        "])\n",
        "outputs = tf.keras.layers.Dense(1)(outputs)\n",
        "training_model = tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir-cn2H_d5R7"
      },
      "source": [
        "You can now train the `training_model` with `tf.keras.Model.fit`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TS3YJ2vnvlW",
        "outputId": "8c2e5cff-eb49-44f5-acac-eba39c349aa0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Train on the preprocessed data.\n",
        "training_model.compile(\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True))\n",
        "training_model.fit(dataset)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 1s 4ms/step - loss: 0.6571\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f89c0b4e190>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pSaEbOE4ecsy"
      },
      "source": [
        "Finally, at inference time, it can be useful to combine these separate stages into a single model that handles raw feature inputs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHjbIZYneboO",
        "outputId": "e667bb6a-2773-4dce-cf06-ce1c320f0852",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inputs = preprocessing_model.input\n",
        "outpus = training_model(preprocessing_model(inputs))\n",
        "inference_model = tf.keras.Model(inputs, outpus)\n",
        "\n",
        "predict_dataset = tf.data.Dataset.from_tensor_slices(predict_features).batch(1)\n",
        "inference_model.predict(predict_dataset)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.49556202]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O01VQIxCWBxU"
      },
      "source": [
        "This composed model can be saved as a [SavedModel](https://www.tensorflow.org/guide/saved_model) for later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6tsyVZgh7Pve",
        "outputId": "20301d31-8bb4-4939-d5f5-561baf6ba945",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "inference_model.save('model')\n",
        "restored_model = tf.keras.models.load_model('model')\n",
        "restored_model.predict(predict_dataset)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
            "INFO:tensorflow:Assets written to: model/assets\n",
            "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.49556202]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXMBwzggwUjI"
      },
      "source": [
        "Note: Preprocessing layers are not trainable, which allows you to apply them *asynchronously* using `tf.data`. This has performence benefits, as you can both [prefetch](https://www.tensorflow.org/guide/data_performance#prefetching) preprocessed batches, and free up any accelerators to focus on the differentiable parts of a model. As this guide shows, seperating preprocessing during training and composing it during inference is a flexible way to leverage these performance gains. However, if your model is small or preprocessing time is negligable, it may be simpler to build preprocessing into a complete model from the start. To do this you can build a single model starting with `tf.keras.Input`, followed by preprocessing layers, followed by trainable layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2pjp7Z18gRCQ"
      },
      "source": [
        "## Feature column equivalence table\n",
        "\n",
        "For reference, here is an approximate correspondence between feature columns and\n",
        "preprocessing layers:<table>\n",
        "  <tr>\n",
        "    <th>Feature Column</th>\n",
        "    <th>Keras Layer</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`feature_column.bucketized_column`</td>\n",
        "    <td>`layers.Discretization`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`feature_column.categorical_column_with_hash_bucket`</td>\n",
        "    <td>`layers.Hashing`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`feature_column.categorical_column_with_identity`</td>\n",
        "    <td>`layers.CategoryEncoding`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`feature_column.categorical_column_with_vocabulary_file`</td>\n",
        "    <td>`layers.StringLookup` or `layers.IntegerLookup`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`feature_column.categorical_column_with_vocabulary_list`</td>\n",
        "    <td>`layers.StringLookup` or `layers.IntegerLookup`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`feature_column.crossed_column`</td>\n",
        "    <td>Not implemented.</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`feature_column.embedding_column`</td>\n",
        "    <td>`layers.Embedding`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`feature_column.indicator_column`</td>\n",
        "    <td>`output_mode='one_hot'` or `output_mode='multi_hot'`*</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`feature_column.numeric_column`</td>\n",
        "    <td>`layers.Normalization`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`feature_column.sequence_categorical_column_with_hash_bucket`</td>\n",
        "    <td>`layers.Hashing`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`feature_column.sequence_categorical_column_with_identity`</td>\n",
        "    <td>`layers.CategoryEncoding`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`feature_column.sequence_categorical_column_with_vocabulary_file`</td>\n",
        "    <td>`layers.StringLookup`, `layers.IntegerLookup`, or `layer.TextVectorization`†</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`feature_column.sequence_categorical_column_with_vocabulary_list`</td>\n",
        "    <td>`layers.StringLookup`, `layers.IntegerLookup`, or `layer.TextVectorization`†</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`feature_column.sequence_numeric_column`</td>\n",
        "    <td>`layers.Normalization`</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>`feature_column.weighted_categorical_column`</td>\n",
        "    <td>`layers.CategoryEncoding`</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "\\* `output_mode` can be passed to `layers.CategoryEncoding`, `layers.StringLookup`, `layers.IntegerLookup`, and `layers.TextVectorization`.\n",
        "\n",
        "† `layers.TextVectorization` can handle freeform text input directly (e.g. entire sentences or paragraphs). This is not one-to-one replacement for categorical sequence handling in TF1, but may offer a convinient replacement for ad-hoc text preprocessing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AQCJ6lM3YDq_"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        " - For more information on keras preprocessing layers, see [the guide to preprocessing layers](https://www.tensorflow.org/guide/keras/preprocessing_layers).\n",
        " - For a more in-depth example of applying preprocessing layers to structured data, see [the structured data tutorial](https://www.tensorflow.org/tutorials/structured_data/preprocessing_layers)."
      ]
    }
  ]
}